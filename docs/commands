If needed, you can connect to the Postgres container:
docker exec -it iot-api-db-1 psql -U iotuser -d iotdb

Check Alerts in Logs
docker compose logs -f alerts
docker compose logs -f web

Rebuild and restart
After making the above two fixes, rebuild and start again:
docker compose down
docker compose build
docker compose up -d

Enter the container:
docker exec -it iot-api-db-1 psql -U iotuser

docker compose down -v
docker compose up -d
-v removes volumes (like pgdata)

Copy models.py into alert_service/
from models import SensorReading, Base

iot-api/
â”œâ”€â”€ Dockerfile  (for web app)
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ alert_service/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ alert_checker.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ __init__.py (optional, if using as module)
â”œâ”€â”€ app.py
â”œâ”€â”€ models.py
â””â”€â”€ ...


Install crontab or use watchdog loop (better)
Instead of using cron inside Docker (which is tricky), modify alert_checker.py to loop forever:

Replace if __name__ == "__main__" block with:
import time

if __name__ == "__main__":
    while True:
        check_alert_conditions()
        time.sleep(60)  # Check every 60 seconds
This way, the container stays alive and continuously checks alerts every minute.


'



ðŸ”„ What You Might Do Next:
If you want to force an alert, you can do one of the following:

Option 1: Insert New Sensor Data Manually (that breaks threshold)
Run this inside your project to simulate a bad reading:
from models import SensorReading, Base
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
import os
from dotenv import load_dotenv

load_dotenv()
DB_URL = os.getenv("DB_URL")
engine = create_engine(DB_URL)
Session = sessionmaker(bind=engine)

session = Session()
reading = SensorReading(temperature=45.0, humidity=15.0)  # High temp, low humidity
session.add(reading)
session.commit()
session.close()

print("ðŸ”§ Inserted test reading.")
Then immediately run:

python -m alert_service.alert_checker
You should see a real alert this time.



 Import and Configure Logging
Place this near the top, just after your existing imports and .env loading:

import logging

# Configure logging
logging.basicConfig(
    filename="alert.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
Step 2: Add Logging Inside check_alert_conditions()
Replace or add these lines in check_alert_conditions():

1. âœ… After reading is fetched and printed:
print(f"Latest Reading: Temp={reading.temperature}Â°C, Humidity={reading.humidity}%, Time={reading.timestamp}")
logging.info("Latest Reading: Temp=%.1fÂ°C, Humidity=%.1f%%, Time=%s", reading.temperature, reading.humidity, str(reading.timestamp))
2. âœ… If no new reading (already alerted):
Replace:

print("ï¿½ Skipping: No new data since last alert.")
With:

print("ï¿½ Skipping: No new data since last alert.")
logging.warning("Skipping: No new data since last alert.")








 Automatically Trigger Alerts Every Minute Using Cron
Step 1: Make alert_checker.py Executable
Edit the first line of alert_checker.py so it can run as a standalone script:

Add this shebang at the top (line 1):
#!/usr/bin/env python3

Now make it executable:
chmod +x alert_service/alert_checker.py


